{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIndexValues(dataSlice):\n",
    "    \"\"\"\n",
    "        Checks if a slice of a pandas data series is simply the row numbers, exported previously\n",
    "        as an index column.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataSlice: pandas data series\n",
    "            A slice of data or list\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        boolean\n",
    "            True if data values are indices based on row number\n",
    "            False if data values are not indices based on row number\n",
    "    \"\"\"\n",
    "    for idx, val in enumerate(dataSlice):\n",
    "        if val != idx+1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "Index values of list: True\n",
      "[5, 2, 1, 0]\n",
      "Index values of list: False\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print([1,2,3,4])\n",
    "print(f\"Index values of list: {checkIndexValues([1,2,3,4])}\")\n",
    "print([5,2,1,0])\n",
    "print(f\"Index values of list: {checkIndexValues([5,2,1,0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfHasLeadingG(value):\n",
    "    \"\"\"\n",
    "        Checks if the first character in a string value is a \"G\"\n",
    "        and if the rest of the string is an otherwise valid integer. \n",
    "        Used to remove artifact leading \"G\"s from join columns.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        value: string\n",
    "            Value to test\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        boolean\n",
    "            True if has a G leading a valid integer \n",
    "            False if not\n",
    "        \n",
    "    \"\"\"\n",
    "    # This only applies to string values\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "    \n",
    "    # If length is zero, this throws an error\n",
    "    try:\n",
    "        if value[0] != \"G\":\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    # Try to convert the value, sliced from the first index onward to an int\n",
    "    # If succeeds, return true, all other conditions return false\n",
    "    try:\n",
    "        int(value[1:])\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1234\n",
      "Has leading G of example value: True\n",
      "GX1234\n",
      "Has leading G of example value: False\n",
      "1234\n",
      "Has leading G of example value: False\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print('G1234')\n",
    "print(f\"Has leading G of example value: {checkIfHasLeadingG('G1234')}\")\n",
    "print('GX1234')\n",
    "print(f\"Has leading G of example value: {checkIfHasLeadingG('GX1234')}\")\n",
    "print('1234')\n",
    "print(f\"Has leading G of example value: {checkIfHasLeadingG('1234')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferTypes(file):\n",
    "    \"\"\"\n",
    "        Thoroughly checks for numeric values that should remain as strings due to \n",
    "        leading 0s that would otherwise get dropped in pandas import.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file: string\n",
    "            filepath to CSV to open\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        cols: dictionary\n",
    "            Relevant columns and string labels for optional pandas import parameter\n",
    "        \n",
    "    \"\"\"\n",
    "    # Declare outside of scope, since I'm still living in a javascript kinda mind\n",
    "    cols = {}\n",
    "    colNames = []\n",
    "\n",
    "    # Open CSV plainly, no type inference\n",
    "    with open(file, newline='') as csvfile:\n",
    "        # Access and loop through rows\n",
    "        data = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        for idx, row in enumerate(data): \n",
    "            entries = row[0].split(',')\n",
    "            # Loop through entries, ignore blank values (index column)\n",
    "            # Trim extraneous single or double quotes eg: ' \" Value \" '\n",
    "            for entry in entries:\n",
    "                if len(entry) == 0:\n",
    "                    continue \n",
    "                    \n",
    "                if entry[0] == '\"' or entry[0] == '\"':\n",
    "                    entry = entry[1:]\n",
    "                    \n",
    "                if entry[-1] == '\"' or entry[-1] == '\"':\n",
    "                    entry = entry[:-1]\n",
    "            # If on first iteration, use values as column names, and iterate\n",
    "            if idx == 0:\n",
    "                colNames = entries\n",
    "                continue\n",
    "            # Check for string values with leading 0, declare as strings in cols dictionary\n",
    "            for i, val in enumerate(entries):\n",
    "                val = str(val)[1:-1]\n",
    "                if isinstance(val, str) and len(val) > 0 and val[0] == '0':\n",
    "                    try:\n",
    "                        int(val)\n",
    "                        cols[colNames[i]] = 'str'\n",
    "                    except:\n",
    "                        continue\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data_final/PS05_2017_S.csv', '../data_final/PS06_2019_S.csv', '../data_final/DS01_S.csv', '../data_final/BE03_T.csv', '../data_final/BE03_C.csv']\n"
     ]
    }
   ],
   "source": [
    "# Use glob to find all files that match file pattern\n",
    "files = glob('../data_final/*.csv')\n",
    "print(files[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types for ../data_final/PS05_2017_S.csv\n",
      "{'Year': 'str'}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(f'Types for {files[0]}')\n",
    "print(inferTypes(files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectedLengths = {\n",
    "    'C':5,\n",
    "    'Z':5,\n",
    "    'T':11,\n",
    "    'S':2\n",
    "}\n",
    "\n",
    "joinCols = {\n",
    "    'C':'COUNTYFP',\n",
    "    'Z':'ZCTA',\n",
    "    'T':'GEOID',\n",
    "    'S':'STATEFP',\n",
    "}\n",
    "\n",
    "expectedColumnLengths = [\n",
    "    {\n",
    "        \"name\":'COUNTYFP',\n",
    "        \"length\":5\n",
    "    },\n",
    "    {\n",
    "        \"name\":'STATEFP',\n",
    "        \"length\":2\n",
    "    },\n",
    "    {\n",
    "        \"name\":'ZCTA',\n",
    "        \"length\":5\n",
    "    },\n",
    "    {\n",
    "        \"name\":'GEOID',\n",
    "        \"length\":11\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def pad(x, length):\n",
    "    try:\n",
    "        if len(f\"{x}\") == length:\n",
    "            return x\n",
    "        \n",
    "        if len(f\"{x}\") > length:\n",
    "            return f\"{x}\"[len(f\"{x}\")-length:]\n",
    "        \n",
    "        if len(f\"{x}\") != length:\n",
    "            return f\"0{x}\"\n",
    "    except:\n",
    "        return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = ['../data_final/EC04_T.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main loop!\n",
    "# High level: Open each file, infer types. \n",
    "# Find index column, drop it. \n",
    "# Find leading G's, remove them.\n",
    "\n",
    "# Start by looping through each fie\n",
    "for file in files:\n",
    "    \n",
    "    # Infer types in order to figure out which numeric fields need to remain strings\n",
    "    types = inferTypes(file)\n",
    "    # Use those types and read in to pandas\n",
    "    raw = pd.read_csv(file, encoding='latin-1', dtype=types)\n",
    "    \n",
    "    # Find the join column based on the last character before the file extension\n",
    "    try:\n",
    "        joinCol = joinCols[file.split('.csv')[0][-1]]\n",
    "    # Others have it in the middle - (ツ)_/¯\n",
    "    except:\n",
    "        joinCol = joinCols[file.split('_')[2]]\n",
    "    \n",
    "    # IF the join column is not as expected, something is wrong. Some have a vestigial GISJOIN column\n",
    "    # Otherwise, flag this to check out after the back\n",
    "    if joinCol not in list(raw.columns):\n",
    "        print(f'Warning - {file} does not have the proper join column')\n",
    "        if 'GISJOIN' in list(raw.columns):\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    for column in raw.columns:\n",
    "        # If the dreaded GISJOIN, change the column name to the appropriate geographic join\n",
    "        if column == 'GISJOIN':\n",
    "            raw = raw.drop(columns=[joinCol])\n",
    "            tempColumns = list(raw.columns)\n",
    "            tempColumns[list(raw.columns).index('GISJOIN')] = joinCol\n",
    "            raw.columns = tempColumns\n",
    "            column = joinCol\n",
    "            \n",
    "        # Markers of an unnamed index column to be removed\n",
    "        if (column == 'Unnamed: 0' or column == 'X') and checkIndexValues(raw[column][0:10]):\n",
    "            raw = raw.drop(columns=[column])\n",
    "            continue\n",
    "            \n",
    "        # Find leading G\n",
    "        if checkIfHasLeadingG(raw[column][0]):\n",
    "            raw.loc[:,column] = raw.loc[:,column].str.slice(1,-1)\n",
    "    \n",
    "    # This section is meant to appropriately pad with leading zeroes\n",
    "    # However, some columns are not formatted consistently, such as just a county code, not state+county for countyFP\n",
    "    # Better solution needed.\n",
    "#     for col in expectedColumnLengths:\n",
    "#         if col['name'] in list(raw.columns):\n",
    "#             raw.loc[:, col['name']] = raw.loc[:, col['name']].apply(lambda x: pad(x, col['length']))\n",
    "    \n",
    "#     # Check for un-concatenated county and state fp columns\n",
    "#     if 'STATEFP' in list(raw.columns) and 'COUNTYFP' in list(raw.columns):\n",
    "#         if len(raw.iloc[0].COUNTYFP) == 3:\n",
    "#             raw['COUNTYFP'] = raw['STATEFP'].astype(str) + raw['COUNTYFP']\n",
    "            \n",
    "#     # Correct missing or null STATEFP based on geoid or countyfp\n",
    "#     if 'STATEFP' in list(raw.columns):\n",
    "#         if 'GEOID' in list(raw.columns):\n",
    "#             raw['STATEFP'] = raw['GEOID'].astype(str).str.slice(0,2)\n",
    "#         elif 'COUNTYFP' in list(raw.columns):\n",
    "#             raw['STATEFP'] = raw['COUNTYFP'].astype(str).str.slice(0,2)\n",
    "            \n",
    "#     # Correct missing or null STATEFP based on geoid or countyfp\n",
    "#     if 'COUNTYFP' in list(raw.columns):\n",
    "#         if 'GEOID' in list(raw.columns):\n",
    "#             raw['COUNTYFP'] = raw['GEOID'].astype(str).str.slice(0,5)\n",
    "            \n",
    "    raw.round(2).to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name1</th>\n",
       "      <th>name2</th>\n",
       "      <th>street1</th>\n",
       "      <th>street2</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip4</th>\n",
       "      <th>category</th>\n",
       "      <th>countyGEOID</th>\n",
       "      <th>countyName</th>\n",
       "      <th>source</th>\n",
       "      <th>geom</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1601 West 4th Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coffeyville</td>\n",
       "      <td>KS</td>\n",
       "      <td>67337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buprenorphine</td>\n",
       "      <td>20125.0</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>SAMHSA</td>\n",
       "      <td>c(-95.64145</td>\n",
       "      <td>37.0402928)</td>\n",
       "      <td>-95.641450</td>\n",
       "      <td>37.040293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3751 West Main Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Independence</td>\n",
       "      <td>KS</td>\n",
       "      <td>67301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buprenorphine</td>\n",
       "      <td>20125.0</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>SAMHSA</td>\n",
       "      <td>c(-95.7566357</td>\n",
       "      <td>37.2256576)</td>\n",
       "      <td>-95.756636</td>\n",
       "      <td>37.225658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bartlesville</td>\n",
       "      <td>4100 SE Adams Road</td>\n",
       "      <td>Suite E-108</td>\n",
       "      <td>Bartlesville</td>\n",
       "      <td>OK</td>\n",
       "      <td>74006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buprenorphine</td>\n",
       "      <td>40147.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>SAMHSA</td>\n",
       "      <td>c(-95.9301563</td>\n",
       "      <td>36.7455475)</td>\n",
       "      <td>-95.930156</td>\n",
       "      <td>36.745548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bartlesville Rightway Medical</td>\n",
       "      <td>610 West Hensley Boulevard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bartlesville</td>\n",
       "      <td>OK</td>\n",
       "      <td>74003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buprenorphine</td>\n",
       "      <td>40147.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>SAMHSA</td>\n",
       "      <td>c(-95.9840426</td>\n",
       "      <td>36.7535489)</td>\n",
       "      <td>-95.984043</td>\n",
       "      <td>36.753549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>410 West Main Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barnsdall</td>\n",
       "      <td>OK</td>\n",
       "      <td>74002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buprenorphine</td>\n",
       "      <td>40113.0</td>\n",
       "      <td>Osage</td>\n",
       "      <td>SAMHSA</td>\n",
       "      <td>c(-96.1618624</td>\n",
       "      <td>36.5618247)</td>\n",
       "      <td>-96.161862</td>\n",
       "      <td>36.561825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4120 Meridian St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bellingham</td>\n",
       "      <td>WA</td>\n",
       "      <td>98226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>naltrexone/vivitrol</td>\n",
       "      <td>53073.0</td>\n",
       "      <td>Whatcom</td>\n",
       "      <td>vivitrolWeb</td>\n",
       "      <td>c(-122.485187967534</td>\n",
       "      <td>48.7909350026357)</td>\n",
       "      <td>-122.485188</td>\n",
       "      <td>48.790935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1815 MAIN ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ferndale</td>\n",
       "      <td>WA</td>\n",
       "      <td>98248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>naltrexone/vivitrol</td>\n",
       "      <td>53073.0</td>\n",
       "      <td>Whatcom</td>\n",
       "      <td>vivitrolWeb</td>\n",
       "      <td>c(-122.580530020679</td>\n",
       "      <td>48.8433449896254)</td>\n",
       "      <td>-122.580530</td>\n",
       "      <td>48.843345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8071 GUIDE MERIDIAN ROAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lynden</td>\n",
       "      <td>WA</td>\n",
       "      <td>98264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>naltrexone/vivitrol</td>\n",
       "      <td>53073.0</td>\n",
       "      <td>Whatcom</td>\n",
       "      <td>vivitrolWeb</td>\n",
       "      <td>c(-122.487691977288</td>\n",
       "      <td>48.9342380123838)</td>\n",
       "      <td>-122.487692</td>\n",
       "      <td>48.934238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42161</th>\n",
       "      <td>NaN</td>\n",
       "      <td>401 2nd Ave.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rolette</td>\n",
       "      <td>ND</td>\n",
       "      <td>58366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>naltrexone/vivitrol</td>\n",
       "      <td>38079.0</td>\n",
       "      <td>Rolette</td>\n",
       "      <td>vivitrolWeb</td>\n",
       "      <td>c(-99.8463525946865</td>\n",
       "      <td>48.6620162483217)</td>\n",
       "      <td>-99.846353</td>\n",
       "      <td>48.662016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42171</th>\n",
       "      <td>NaN</td>\n",
       "      <td>114 3rd St. NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rolla</td>\n",
       "      <td>ND</td>\n",
       "      <td>58367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>naltrexone/vivitrol</td>\n",
       "      <td>38079.0</td>\n",
       "      <td>Rolette</td>\n",
       "      <td>vivitrolWeb</td>\n",
       "      <td>c(-99.6137526689196</td>\n",
       "      <td>48.8613428377625)</td>\n",
       "      <td>-99.613753</td>\n",
       "      <td>48.861343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14773 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name1                       name2      street1  \\\n",
       "1                                NaN        1601 West 4th Street          NaN   \n",
       "2                                NaN       3751 West Main Street          NaN   \n",
       "3                       Bartlesville          4100 SE Adams Road  Suite E-108   \n",
       "4      Bartlesville Rightway Medical  610 West Hensley Boulevard          NaN   \n",
       "5                                NaN        410 West Main Street          NaN   \n",
       "...                              ...                         ...          ...   \n",
       "42131                            NaN            4120 Meridian St          NaN   \n",
       "42141                            NaN                1815 MAIN ST          NaN   \n",
       "42151                            NaN    8071 GUIDE MERIDIAN ROAD          NaN   \n",
       "42161                            NaN                401 2nd Ave.          NaN   \n",
       "42171                            NaN              114 3rd St. NE          NaN   \n",
       "\n",
       "            street2 city  state  zip                 zip4  category  \\\n",
       "1       Coffeyville   KS  67337  NaN        buprenorphine   20125.0   \n",
       "2      Independence   KS  67301  NaN        buprenorphine   20125.0   \n",
       "3      Bartlesville   OK  74006  NaN        buprenorphine   40147.0   \n",
       "4      Bartlesville   OK  74003  NaN        buprenorphine   40147.0   \n",
       "5         Barnsdall   OK  74002  NaN        buprenorphine   40113.0   \n",
       "...             ...  ...    ...  ...                  ...       ...   \n",
       "42131    Bellingham   WA  98226  NaN  naltrexone/vivitrol   53073.0   \n",
       "42141      Ferndale   WA  98248  NaN  naltrexone/vivitrol   53073.0   \n",
       "42151        Lynden   WA  98264  NaN  naltrexone/vivitrol   53073.0   \n",
       "42161       Rolette   ND  58366  NaN  naltrexone/vivitrol   38079.0   \n",
       "42171         Rolla   ND  58367  NaN  naltrexone/vivitrol   38079.0   \n",
       "\n",
       "      countyGEOID   countyName               source                geom  \\\n",
       "1      Montgomery       SAMHSA          c(-95.64145         37.0402928)   \n",
       "2      Montgomery       SAMHSA        c(-95.7566357         37.2256576)   \n",
       "3      Washington       SAMHSA        c(-95.9301563         36.7455475)   \n",
       "4      Washington       SAMHSA        c(-95.9840426         36.7535489)   \n",
       "5           Osage       SAMHSA        c(-96.1618624         36.5618247)   \n",
       "...           ...          ...                  ...                 ...   \n",
       "42131     Whatcom  vivitrolWeb  c(-122.485187967534   48.7909350026357)   \n",
       "42141     Whatcom  vivitrolWeb  c(-122.580530020679   48.8433449896254)   \n",
       "42151     Whatcom  vivitrolWeb  c(-122.487691977288   48.9342380123838)   \n",
       "42161     Rolette  vivitrolWeb  c(-99.8463525946865   48.6620162483217)   \n",
       "42171     Rolette  vivitrolWeb  c(-99.6137526689196   48.8613428377625)   \n",
       "\n",
       "        Longitude   Latitude  \n",
       "1      -95.641450  37.040293  \n",
       "2      -95.756636  37.225658  \n",
       "3      -95.930156  36.745548  \n",
       "4      -95.984043  36.753549  \n",
       "5      -96.161862  36.561825  \n",
       "...           ...        ...  \n",
       "42131 -122.485188  48.790935  \n",
       "42141 -122.580530  48.843345  \n",
       "42151 -122.487692  48.934238  \n",
       "42161  -99.846353  48.662016  \n",
       "42171  -99.613753  48.861343  \n",
       "\n",
       "[14773 rows x 15 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = pd.read_csv('../data_final/EC04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw['COUNTYFP'] = rw['GEOID'].astype(str).str.slice(0,2) + rw['GEOID'].astype(str).str.slice(3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw['COUNTYFP'] = rw['COUNTYFP'].apply(lambda x: pad(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = rw.drop(columns=[\"GEOID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw.to_csv('../data_final/DS04_C.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
