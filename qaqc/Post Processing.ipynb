{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIndexValues(dataSlice):\n",
    "    \"\"\"\n",
    "        Checks if a slice of a pandas data series is simply the row numbers, exported previously\n",
    "        as an index column.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataSlice: pandas data series\n",
    "            A slice of data or list\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        boolean\n",
    "            True if data values are indices based on row number\n",
    "            False if data values are not indices based on row number\n",
    "    \"\"\"\n",
    "    for idx, val in enumerate(dataSlice):\n",
    "        if val != idx+1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "Index values of list: True\n",
      "[5, 2, 1, 0]\n",
      "Index values of list: False\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print([1,2,3,4])\n",
    "print(f\"Index values of list: {checkIndexValues([1,2,3,4])}\")\n",
    "print([5,2,1,0])\n",
    "print(f\"Index values of list: {checkIndexValues([5,2,1,0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfHasLeadingG(value):\n",
    "    \"\"\"\n",
    "        Checks if the first character in a string value is a \"G\"\n",
    "        and if the rest of the string is an otherwise valid integer. \n",
    "        Used to remove artifact leading \"G\"s from join columns.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        value: string\n",
    "            Value to test\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        boolean\n",
    "            True if has a G leading a valid integer \n",
    "            False if not\n",
    "        \n",
    "    \"\"\"\n",
    "    # This only applies to string values\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "    \n",
    "    # If length is zero, this throws an error\n",
    "    try:\n",
    "        if value[0] != \"G\":\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    # Try to convert the value, sliced from the first index onward to an int\n",
    "    # If succeeds, return true, all other conditions return false\n",
    "    try:\n",
    "        int(value[1:])\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1234\n",
      "Has leading G of example value: True\n",
      "GX1234\n",
      "Has leading G of example value: False\n",
      "1234\n",
      "Has leading G of example value: False\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print('G1234')\n",
    "print(f\"Has leading G of example value: {checkIfHasLeadingG('G1234')}\")\n",
    "print('GX1234')\n",
    "print(f\"Has leading G of example value: {checkIfHasLeadingG('GX1234')}\")\n",
    "print('1234')\n",
    "print(f\"Has leading G of example value: {checkIfHasLeadingG('1234')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferTypes(file):\n",
    "    \"\"\"\n",
    "        Thoroughly checks for numeric values that should remain as strings due to \n",
    "        leading 0s that would otherwise get dropped in pandas import.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file: string\n",
    "            filepath to CSV to open\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        cols: dictionary\n",
    "            Relevant columns and string labels for optional pandas import parameter\n",
    "        \n",
    "    \"\"\"\n",
    "    # Declare outside of scope, since I'm still living in a javascript kinda mind\n",
    "    cols = {}\n",
    "    colNames = []\n",
    "\n",
    "    # Open CSV plainly, no type inference\n",
    "    with open(file, newline='') as csvfile:\n",
    "        # Access and loop through rows\n",
    "        data = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        for idx, row in enumerate(data): \n",
    "            entries = row[0].split(',')\n",
    "            # Loop through entries, ignore blank values (index column)\n",
    "            # Trim extraneous single or double quotes eg: ' \" Value \" '\n",
    "            for entry in entries:\n",
    "                if len(entry) == 0:\n",
    "                    continue \n",
    "                    \n",
    "                if entry[0] == '\"' or entry[0] == '\"':\n",
    "                    entry = entry[1:]\n",
    "                    \n",
    "                if entry[-1] == '\"' or entry[-1] == '\"':\n",
    "                    entry = entry[:-1]\n",
    "            # If on first iteration, use values as column names, and iterate\n",
    "            if idx == 0:\n",
    "                colNames = entries\n",
    "                continue\n",
    "            # Check for string values with leading 0, declare as strings in cols dictionary\n",
    "            for i, val in enumerate(entries):\n",
    "                val = str(val)[1:-1]\n",
    "                if isinstance(val, str) and len(val) > 0 and val[0] == '0':\n",
    "                    try:\n",
    "                        int(val)\n",
    "                        cols[colNames[i]] = 'str'\n",
    "                    except:\n",
    "                        continue\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data_final/PS05_2017_S.csv', '../data_final/PS06_2019_S.csv', '../data_final/DS01_S.csv', '../data_final/BE03_T.csv', '../data_final/BE03_C.csv']\n"
     ]
    }
   ],
   "source": [
    "# Use glob to find all files that match file pattern\n",
    "files = glob('../data_final/*.csv')\n",
    "print(files[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types for ../data_final/PS05_2017_S.csv\n",
      "{'Year': 'str'}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(f'Types for {files[0]}')\n",
    "print(inferTypes(files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectedLengths = {\n",
    "    'C':5,\n",
    "    'Z':5,\n",
    "    'T':11,\n",
    "    'S':2\n",
    "}\n",
    "\n",
    "joinCols = {\n",
    "    'C':'COUNTYFP',\n",
    "    'Z':'ZCTA',\n",
    "    'T':'GEOID',\n",
    "    'S':'STATEFP',\n",
    "}\n",
    "\n",
    "expectedColumnLengths = [\n",
    "    {\n",
    "        \"name\":'COUNTYFP',\n",
    "        \"length\":5\n",
    "    },\n",
    "    {\n",
    "        \"name\":'STATEFP',\n",
    "        \"length\":2\n",
    "    },\n",
    "    {\n",
    "        \"name\":'ZCTA',\n",
    "        \"length\":5\n",
    "    },\n",
    "    {\n",
    "        \"name\":'GEOID',\n",
    "        \"length\":11\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def pad(x, length):\n",
    "    try:\n",
    "        if len(f\"{x}\") == length:\n",
    "            return x\n",
    "        \n",
    "        if len(f\"{x}\") > length:\n",
    "            return f\"{x}\"[len(f\"{x}\")-length:]\n",
    "        \n",
    "        if len(f\"{x}\") != length:\n",
    "            return f\"0{x}\"\n",
    "    except:\n",
    "        return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = ['../data_final/EC04_T.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main loop!\n",
    "# High level: Open each file, infer types. \n",
    "# Find index column, drop it. \n",
    "# Find leading G's, remove them.\n",
    "\n",
    "# Start by looping through each fie\n",
    "for file in files:\n",
    "    \n",
    "    # Infer types in order to figure out which numeric fields need to remain strings\n",
    "    types = inferTypes(file)\n",
    "    # Use those types and read in to pandas\n",
    "    raw = pd.read_csv(file, encoding='latin-1', dtype=types)\n",
    "    \n",
    "    # Find the join column based on the last character before the file extension\n",
    "    try:\n",
    "        joinCol = joinCols[file.split('.csv')[0][-1]]\n",
    "    # Others have it in the middle - (ツ)_/¯\n",
    "    except:\n",
    "        joinCol = joinCols[file.split('_')[2]]\n",
    "    \n",
    "    # IF the join column is not as expected, something is wrong. Some have a vestigial GISJOIN column\n",
    "    # Otherwise, flag this to check out after the back\n",
    "    if joinCol not in list(raw.columns):\n",
    "        print(f'Warning - {file} does not have the proper join column')\n",
    "        if 'GISJOIN' in list(raw.columns):\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    for column in raw.columns:\n",
    "        # If the dreaded GISJOIN, change the column name to the appropriate geographic join\n",
    "        if column == 'GISJOIN':\n",
    "            raw = raw.drop(columns=[joinCol])\n",
    "            tempColumns = list(raw.columns)\n",
    "            tempColumns[list(raw.columns).index('GISJOIN')] = joinCol\n",
    "            raw.columns = tempColumns\n",
    "            column = joinCol\n",
    "            \n",
    "        # Markers of an unnamed index column to be removed\n",
    "        if (column == 'Unnamed: 0' or column == 'X') and checkIndexValues(raw[column][0:10]):\n",
    "            raw = raw.drop(columns=[column])\n",
    "            continue\n",
    "            \n",
    "        # Find leading G\n",
    "        if checkIfHasLeadingG(raw[column][0]):\n",
    "            raw.loc[:,column] = raw.loc[:,column].str.slice(1,-1)\n",
    "    \n",
    "    # This section is meant to appropriately pad with leading zeroes\n",
    "    # However, some columns are not formatted consistently, such as just a county code, not state+county for countyFP\n",
    "    # Better solution needed.\n",
    "#     for col in expectedColumnLengths:\n",
    "#         if col['name'] in list(raw.columns):\n",
    "#             raw.loc[:, col['name']] = raw.loc[:, col['name']].apply(lambda x: pad(x, col['length']))\n",
    "    \n",
    "#     # Check for un-concatenated county and state fp columns\n",
    "#     if 'STATEFP' in list(raw.columns) and 'COUNTYFP' in list(raw.columns):\n",
    "#         if len(raw.iloc[0].COUNTYFP) == 3:\n",
    "#             raw['COUNTYFP'] = raw['STATEFP'].astype(str) + raw['COUNTYFP']\n",
    "            \n",
    "#     # Correct missing or null STATEFP based on geoid or countyfp\n",
    "#     if 'STATEFP' in list(raw.columns):\n",
    "#         if 'GEOID' in list(raw.columns):\n",
    "#             raw['STATEFP'] = raw['GEOID'].astype(str).str.slice(0,2)\n",
    "#         elif 'COUNTYFP' in list(raw.columns):\n",
    "#             raw['STATEFP'] = raw['COUNTYFP'].astype(str).str.slice(0,2)\n",
    "            \n",
    "#     # Correct missing or null STATEFP based on geoid or countyfp\n",
    "#     if 'COUNTYFP' in list(raw.columns):\n",
    "#         if 'GEOID' in list(raw.columns):\n",
    "#             raw['COUNTYFP'] = raw['GEOID'].astype(str).str.slice(0,5)\n",
    "            \n",
    "    raw.round(2).to_csv(file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
