{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Scraper\n",
    "##### Yingyi Liang (Aug, 2020)\n",
    "- Scrape text from PDF using distribution of text, appropriate for PDF which has similar structures each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackabuse.com/working-with-pdfs-in-python-reading-and-splitting-pages/\n",
    "#https://github.com/pymupdf/PyMuPDF\n",
    "#doc[20].getFontList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split text data into boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- directory_1980_drug.pdf -----\n",
      "# of pages:\t172\n",
      "Page size:\t615.5999755859375 * 811.2000122070312\n",
      "Warning: page size not uniform\n"
     ]
    }
   ],
   "source": [
    "#import sample PDF\n",
    "filename = \"directory_1980_drug.pdf\"\n",
    "\n",
    "doc = fitz.open(filename)\n",
    "print('----- {0} -----\\n# of pages:\\t{1}\\nPage size:\\t{2} * {3}'\\\n",
    "      .format(filename, len(doc), doc[0].bound()[2], doc[0].bound()[3]))\n",
    "if (doc[0].bound()[2] != doc[10].bound()[2]):\n",
    "    print('Warning: page size not uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 1980\n",
    "#keys\n",
    "abbr_keys = {'Drug': 'Drug', 'Alcoholism': 'Alcoholism'}\n",
    "#save dictionary\n",
    "np.save('keys.npy'.format(YEAR), abbr_keys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seps(coords, dist, plot = False):\n",
    "    '''\n",
    "    Finds gaps in coords greater than a given dist.\n",
    "    Inputs:\n",
    "        coords(list): list of numbers\n",
    "        dist(int/float): distance between numbers to be considered a gap\n",
    "        plot(boolean): if True, a histgram of the coordinates and seperation will be plotted\n",
    "    Returns:\n",
    "        A list of floats indication seperations.\n",
    "    '''\n",
    "    coords.sort()\n",
    "    coords = np.array(coords)\n",
    "    seps = (coords[:-1][np.diff(coords) > dist] + coords[1:][np.diff(coords) > dist])/2\n",
    "    print(seps)\n",
    "    seps_valid = []\n",
    "    lb = 0\n",
    "    for sep in seps:\n",
    "        if len(coords[(coords > sep) & (coords < sep + 30)]) > 40:\n",
    "            seps_valid.append(sep)\n",
    "        lb = sep\n",
    "    if plot:\n",
    "        plt.hist(coords, bins = 100)\n",
    "        for sep in seps_valid:\n",
    "            plt.axvline(sep, color='black')\n",
    "    return seps_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seps(coords, dist, plot = False):\n",
    "    '''\n",
    "    Finds gaps in coords greater than a given dist.\n",
    "    Inputs:\n",
    "        coords(list): list of numbers\n",
    "        dist(int/float): distance between numbers to be considered a gap\n",
    "        plot(boolean): if True, a histgram of the coordinates and seperation will be plotted\n",
    "    Returns:\n",
    "        A list of floats indication seperations.\n",
    "    '''\n",
    "    coords.sort()\n",
    "    coords = np.array(coords)\n",
    "    seps = coords[1:][np.diff(coords) > dist]\n",
    "    #print(seps)\n",
    "    sep1 = []\n",
    "    sep2 = []\n",
    "    for sep in seps:\n",
    "        if len(coords[(coords > sep) & (coords < sep + 20)]) > len(words)/10:\n",
    "            if (sep > 190 and sep < 235):\n",
    "                sep1 = [sep - 5]\n",
    "            if (sep > 370 and sep < 415):\n",
    "                sep2 = [sep - 5]\n",
    "    seps_valid = sep1 + sep2\n",
    "    if plot:\n",
    "        plt.hist(coords, bins = 100)\n",
    "        for sep in seps_valid:\n",
    "            plt.axvline(sep, color='black')\n",
    "    return seps_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstpagen = 22\n",
    "# words = doc[firstpagen - 1].getText(\"words\")\n",
    "# find_seps([word[0] for word in words], 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = doc[39 - 1].getText(\"words\")\n",
    "# find_seps([word[0] for word in words], 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Organize lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fc5575efb50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check page\n",
    "words = []\n",
    "for pagen in range(30, 70):\n",
    "    words += doc[pagen - 1].getText(\"words\")\n",
    "plt.hist([word[1] for word in words], bins = 120)\n",
    "plt.axvline(40, color='black')  #cut title\n",
    "plt.axvline(695, color='black') #cut page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(text, thr):\n",
    "    '''\n",
    "    Splits a list of into rows.\n",
    "    Inputs:\n",
    "        text: a list of tuple containing individual words and their positions\n",
    "        thr: the distance between lines\n",
    "    Outputs:\n",
    "        List of list that represent rows, arranged by x0 position.\n",
    "    '''\n",
    "    if not text:\n",
    "        return []\n",
    "    \n",
    "    text_remain = text\n",
    "    text_by_row = []\n",
    "    temp = []\n",
    "    while len(text_remain) > 0:\n",
    "        temp_text_remain = []\n",
    "        y0 = text_remain[0][1]\n",
    "        i = 0\n",
    "        while i < len(text_remain):\n",
    "            if (text_remain[i][1] < y0 + thr) and (text_remain[i][1] > y0 - thr):\n",
    "                temp.append(text_remain[i])\n",
    "            else:\n",
    "                temp_text_remain.append(text_remain[i])\n",
    "            i += 1\n",
    "        text_remain = temp_text_remain\n",
    "        temp.sort(key = lambda x: x[2]) #x[0]\n",
    "        text_by_row.append(temp)\n",
    "        temp = []\n",
    "    text_by_row.sort(key = lambda x: x[0][1])\n",
    "    return text_by_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_units(col, dist):\n",
    "    i = 0\n",
    "    splitted = []\n",
    "    while i < len(col):\n",
    "        if i == 0:\n",
    "            m = sum([word[1] for word in col[i]])/len([word[1] for word in col[i]])\n",
    "            l = sum([word[1] for word in col[i + 1]])/len([word[1] for word in col[i + 1]])\n",
    "            if l - m < dist:\n",
    "                temp = [[word[4] for word in col[i]]]\n",
    "            else:\n",
    "                temp = []\n",
    "        elif i < len(col) - 1:\n",
    "            u = sum([word[1] for word in col[i - 1]])/len([word[1] for word in col[i - 1]])\n",
    "            m = sum([word[1] for word in col[i]])/len([word[1] for word in col[i]])\n",
    "            l = sum([word[1] for word in col[i + 1]])/len([word[1] for word in col[i + 1]])\n",
    "            if (m - u) > dist and (l - m) > dist and len(temp) > 3:\n",
    "                pass\n",
    "            #    splitted.append(temp)\n",
    "                #temp = []\n",
    "            elif (m - u) > dist and len(temp) > 3:\n",
    "                splitted.append(temp)\n",
    "                temp = [[word[4] for word in col[i]]]\n",
    "            else:\n",
    "                temp.append([word[4] for word in col[i]])\n",
    "        else:\n",
    "            temp.append([word[4] for word in col[i]])\n",
    "            splitted.append(temp)\n",
    "        i += 1\n",
    "    return [unit for unit in splitted if unit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstpagen = 19\n",
    "data = []\n",
    "for pagen in range(firstpagen, 168):\n",
    "    words = doc[pagen - 1].getText(\"words\")\n",
    "    words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "    seps = find_seps([word[0] for word in words], 10)\n",
    "    cols = []\n",
    "    if not seps: #21\n",
    "        cols.append([word for word in words])\n",
    "    elif len(seps) == 2: #19\n",
    "        cols.append([word for word in words if word[0] < seps[0]])\n",
    "        cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "        cols.append([word for word in words if word[0] > seps[1]])\n",
    "    else: #20\n",
    "        cols.append([word for word in words if word[0] < seps[0]])\n",
    "        cols.append([word for word in words if word[0] > seps[0]])\n",
    "    #print(cols[0])\n",
    "    page = []\n",
    "    for col in cols:\n",
    "        col = split_rows(col, 5)\n",
    "        page.append(split_units(col, 10))\n",
    "    data.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write data into csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- City, state, zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_citystatezip(line):\n",
    "    if len(line) < 3:\n",
    "        return False\n",
    "    line[-2] = line[-2].replace('t1', \"H\").replace('l', 'I')\n",
    "    if line[-1].replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5').replace('&', '6').isnumeric()\\\n",
    "    and len(line[-1]) == 5 and line[-2].isupper() and len(line[-2]) == 2\\\n",
    "    and (line[-3][-1] == ',' or line[-3][-1] == 'â€¢' or line[-3][-1] == '.'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_citystatezip(line):\n",
    "    line[-2] = line[-2].replace('t1', \"H\").replace('l', 'I')\n",
    "    return [' '.join(line[:-2])[:-1], line[-2], line[-1].replace('l', '1').replace('I', '1')\\\n",
    "            .replace('O', '0').replace('S', '5').replace('&', '6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# tests = [\n",
    "#     ['BIRMINGHAM,', 'AL', '35294'],\n",
    "#     ['ATMORE,', 'AL', '36504']\n",
    "# ]\n",
    "\n",
    "# for t in tests:\n",
    "#     print(is_citystatezip(t))\n",
    "#     print(clean_citystatezip(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contact(line):\n",
    "    line = ''.join(line)\n",
    "    if len(line) < 12:\n",
    "        return False\n",
    "    if line[1:4].replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5').replace('&', '6').isnumeric()\\\n",
    "    and line[5:8].replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5').replace('&', '6').isnumeric()\\\n",
    "    and line[8] == '-':\n",
    "        return True\n",
    "\n",
    "def clean_contact(line):\n",
    "    line = ''.join(line)\n",
    "    c = '(' + line[1:4].replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5').replace('&', '6')\\\n",
    "    + ')' + line[5:].replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5').replace('&', '6')\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# tests = [\n",
    "#     ['(2051', '251-2992']\n",
    "# ]\n",
    "\n",
    "# for t in tests:\n",
    "#     print(is_contact(t))\n",
    "#     print(clean_contact(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "address_indicators = ['P.O.', 'P.0.', 'P.O', 'P.0', \\\n",
    "                      'ROAD', 'HIGHWAY', 'ROUTE', 'BUILDING', 'STREET', 'AVENUE', 'SUITE', 'SUITES', 'DRIVE', 'BOULEVARD', 'BLVD', \\\n",
    "                      'ANNEXT', 'STREETS','FLOOR', 'FL', 'BLDG', 'REAR', 'ROOM', 'BASEMENT', 'BUILDING', 'STATION'] ##\n",
    "def is_address(line):\n",
    "    if line[0].replace('-', '').replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5').isnumeric() \\\n",
    "    or any(x in line for x in address_indicators):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_address(line):\n",
    "    if line[0].replace('-', '').replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5').isnumeric():\n",
    "        line[0] = line[0].replace('-', '').replace('l', '1').replace('I', '1').replace('O', '0').replace('S', '5')\n",
    "    return ' '.join(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_col_data(col_text_splitted):\n",
    "    '''\n",
    "    Splits data into list of lists with\n",
    "    name1, name2, address1, address2, city, state, zip, phone, keys\n",
    "    '''\n",
    "    data_holders = []\n",
    "    for facil in col_text_splitted:\n",
    "        if len(facil) < 2:\n",
    "            print(facil)\n",
    "        if len(facil) > 2:\n",
    "            data_holder = []\n",
    "            i = 0 #indicator of next line\n",
    "            #name1\n",
    "            data_holder.append(' '.join(facil[0])) \n",
    "            i += 1\n",
    "            #name2\n",
    "            if not is_address(facil[i]) and not is_citystatezip(facil[i]) and not is_contact(facil[i]): \n",
    "                data_holder.append(' '.join(facil[i])) \n",
    "                i += 1\n",
    "            else:\n",
    "                data_holder.append('')         \n",
    "            #address1\n",
    "            if is_address(facil[i]):\n",
    "                data_holder.append(clean_address(facil[i])) \n",
    "                i += 1\n",
    "            else:\n",
    "                data_holder.append('')\n",
    "            #address2\n",
    "            if not is_citystatezip(facil[i]) and not is_contact(facil[i]):##\n",
    "                data_holder.append(clean_address(facil[i])) \n",
    "                i += 1\n",
    "            else:\n",
    "                data_holder.append('')\n",
    "            #address3\n",
    "            if not is_citystatezip(facil[i]) and not is_contact(facil[i]):##\n",
    "                data_holder.append(clean_address(facil[i])) \n",
    "                i += 1\n",
    "            else:\n",
    "                data_holder.append('')\n",
    "            #city, state, zip\n",
    "            data_holder += clean_citystatezip(facil[i])\n",
    "            i += 1\n",
    "            #contact\n",
    "            if is_contact(facil[i]):\n",
    "                data_holder.append(clean_contact(facil[i]))\n",
    "                i += 1\n",
    "            else:\n",
    "                data_holder.append('')\n",
    "            data_holder.append(facil[-1][0])\n",
    "            \n",
    "            data_holders.append(data_holder)\n",
    "            print(\".\", end = '') #for each MOUD\n",
    "    return data_holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"{}.csv\".format(1980)\n",
    "with open(filename, 'w', newline = '') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Name1\", \"Name2\", \"Address1\", \"Address2\", \"Address3\", \"City\", \"State\", \"ZIP_Code\", \"Contact\", \"Keys\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 19......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 20........ Finished Col ...... Finished Col \n",
      "Page: 21.. Finished Col \n",
      "Page: 22......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 23.......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 24...... Finished Col \n",
      "Page: 25........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 26........ Finished Col ........ Finished Col . Finished Col \n",
      "Page: 27......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 28........ Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 29........ Finished Col ........ Finished Col .......... Finished Col \n",
      "Page: 30......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 31.......... Finished Col ........... Finished Col ........... Finished Col \n",
      "Page: 32.......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 33.......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 34......... Finished Col ......... Finished Col .......... Finished Col \n",
      "Page: 35.......... Finished Col .......... Finished Col .......... Finished Col \n",
      "Page: 36........... Finished Col .......... Finished Col ......... Finished Col \n",
      "Page: 37.......... Finished Col .......... Finished Col ......... Finished Col \n",
      "Page: 38........ Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 39......... Finished Col ...... Finished Col \n",
      "Page: 40........ Finished Col .......... Finished Col ........ Finished Col \n",
      "Page: 41........ Finished Col \n",
      "Page: 42.......... Finished Col ........ Finished Col ........... Finished Col \n",
      "Page: 43......... Finished Col .......... Finished Col ........ Finished Col \n",
      "Page: 44.......... Finished Col ......... Finished Col \n",
      "Page: 45......... Finished Col \n",
      "Page: 46......... Finished Col ...... Finished Col \n",
      "Page: 47......... Finished Col .......... Finished Col ......... Finished Col \n",
      "Page: 48......... Finished Col .......... Finished Col .......... Finished Col \n",
      "Page: 49......... Finished Col ........ Finished Col .......... Finished Col \n",
      "Page: 50....... Finished Col \n",
      "Page: 51......... Finished Col .......... Finished Col ........ Finished Col \n",
      "Page: 52........ Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 53....... Finished Col \n",
      "Page: 54......... Finished Col ........ Finished Col \n",
      "Page: 55........ Finished Col \n",
      "Page: 56.. Finished Col \n",
      "Page: 57......... Finished Col ........... Finished Col ........ Finished Col \n",
      "Page: 58......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 59....... Finished Col \n",
      "Page: 60......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 61........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 62..... Finished Col \n",
      "Page: 63......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 64... Finished Col \n",
      "Page: 65........ Finished Col ......... Finished Col .......... Finished Col \n",
      "Page: 66.. Finished Col \n",
      "Page: 67........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 68........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 69......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 70......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 71........ Finished Col .. Finished Col \n",
      "Page: 72......... Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 73.......... Finished Col ......... Finished Col .... Finished Col \n",
      "Page: 74........ Finished Col ... Finished Col \n",
      "Page: 75......... Finished Col ........... Finished Col ......... Finished Col \n",
      "Page: 76........ Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 77........ Finished Col ......... Finished Col . Finished Col \n",
      "Page: 78......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 79......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 80......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 81......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 82...... Finished Col \n",
      "Page: 83........ Finished Col ......... Finished Col .......... Finished Col \n",
      "Page: 84.......... Finished Col .......... Finished Col ......... Finished Col \n",
      "Page: 85......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 86......... Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 87......... Finished Col ....... Finished Col \n",
      "Page: 88........ Finished Col ......... Finished Col .......... Finished Col \n",
      "Page: 89......... Finished Col .......... Finished Col ........ Finished Col \n",
      "Page: 90........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 91........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 92....... Finished Col \n",
      "Page: 93......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 94......... Finished Col ....... Finished Col \n",
      "Page: 95........ Finished Col ..... Finished Col \n",
      "Page: 96........ Finished Col ......... Finished Col ... Finished Col \n",
      "Page: 97......... Finished Col .......... Finished Col . Finished Col \n",
      "Page: 98........ Finished Col ........ Finished Col .... Finished Col \n",
      "Page: 99........ Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 100........ Finished Col ......... Finished Col .......... Finished Col \n",
      "Page: 101.......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 102. Finished Col \n",
      "Page: 103......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 104....... Finished Col \n",
      "Page: 105.......... Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 106.......... Finished Col .......... Finished Col ........... Finished Col \n",
      "Page: 107.......... Finished Col .......... Finished Col ........ Finished Col \n",
      "Page: 108........ Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 109........ Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 110......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 111........ Finished Col .......... Finished Col .......... Finished Col \n",
      "Page: 112.......... Finished Col .......... Finished Col .......... Finished Col \n",
      "Page: 113.......... Finished Col ........... Finished Col .......... Finished Col \n",
      "Page: 114.......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 115......... Finished Col ........ Finished Col .......... Finished Col \n",
      "Page: 116........ Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 117........ Finished Col ....... Finished Col \n",
      "Page: 118......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 119........ Finished Col ..... Finished Col \n",
      "Page: 120...... Finished Col \n",
      "Page: 121........ Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 122.......... Finished Col .......... Finished Col ........... Finished Col \n",
      "Page: 123.......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 124........ Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 125......... Finished Col ........ Finished Col \n",
      "Page: 126........ Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 127......... Finished Col ........ Finished Col \n",
      "Page: 128....... Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 129....... Finished Col \n",
      "Page: 130........ Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 131......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 132......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 133........ Finished Col .......... Finished Col .......... Finished Col \n",
      "Page: 134.......... Finished Col .......... Finished Col .......... Finished Col \n",
      "Page: 135........ Finished Col ........ Finished Col ....... Finished Col \n",
      "Page: 136......... Finished Col ..... Finished Col \n",
      "Page: 137........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 138....... Finished Col ....... Finished Col ........ Finished Col \n",
      "Page: 139. Finished Col \n",
      "Page: 140....... Finished Col \n",
      "Page: 141......... Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 142......... Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 143.......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 144......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 145.......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 146....... Finished Col \n",
      "Page: 147........ Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 148.......... Finished Col \n",
      "Page: 149........ Finished Col ..... Finished Col \n",
      "Page: 150......... Finished Col ........ Finished Col ........ Finished Col \n",
      "Page: 151......... Finished Col ........ Finished Col \n",
      "Page: 152........ Finished Col ....... Finished Col ........ Finished Col \n",
      "Page: 153....... Finished Col ......... Finished Col .......... Finished Col \n",
      "Page: 154......... Finished Col ......... Finished Col \n",
      "Page: 155........ Finished Col ........ Finished Col \n",
      "Page: 156........ Finished Col ......... Finished Col ........ Finished Col \n",
      "Page: 157.......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 158........ Finished Col ........ Finished Col ......... Finished Col \n",
      "Page: 159........ Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 160...... Finished Col \n",
      "Page: 161........ Finished Col ........ Finished Col \n",
      "Page: 162......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 163........ Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 164......... Finished Col ......... Finished Col .......... Finished Col \n",
      "Page: 165......... Finished Col ......... Finished Col ......... Finished Col \n",
      "Page: 166. Finished Col \n",
      "Page: 167... Finished Col .. Finished Col \n"
     ]
    }
   ],
   "source": [
    "pagen = 19\n",
    "\n",
    "for page in data:\n",
    "    print(\"Page:\", pagen, end = '')\n",
    "    page_data_holders = []\n",
    "    for col in page:\n",
    "        if col != []:\n",
    "            page_data_holders += clean_col_data(col)\n",
    "            print(\" Finished Col \", end = '')\n",
    "    with open(filename, 'a', newline = '') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(page_data_holders)\n",
    "    pagen += 1\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check error data\n",
    "#data[117 - 19][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rewrite data in problem pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[101 - 19][0][0][2] = ['PATERSON,', 'NJ', '07501']\n",
    "data[90 - 19][2][2][4] = ['GREENWOOD,', 'MS', '38701']\n",
    "data[117 - 19][0][1][5] = ['(516)', '781-1911']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[73 - 19][2][3] = [['WINNFIELD SUBSTANCE ABUSE SERVICES'],\n",
    "    ['WINNFIELD,', 'LA', '71483'],\n",
    " ['1', '318', 'l', '628-2770'],\n",
    " ['Alcoholism/Drug', 'Abuse', 'Treatment', 'Unit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[52 - 19][2][-1] = [['VISTA', 'HALL'],\n",
    " ['OGEECHEE', 'OUTPATIENT', 'PROGRAM'],\n",
    " ['236', 'VISTA', 'CIRCLE'],\n",
    " ['P.O.', 'BOX', '694'],\n",
    " ['STATESBORO,', 'GA', '30458'],\n",
    " ['C', '912', 'l', '764-6129'],\n",
    " ['Alcoholism/Drug', 'Abuse', 'Treatment', 'Unit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[43 - 19][0][3][2] = ['MANCHESTER,', 'CT', '06040']\n",
    "data[37 - 19][0][0][3] = ['SAN', 'RAFAEL,', 'CA', '94901']\n",
    "data[37 - 19][0][1][2] = ['SAN', 'RAFAEL,', 'CA', '94901']\n",
    "data[54 - 19][0][2][2] = ['HILO,', 'HI', '96720']\n",
    "data[57 - 19][1][1][3] = ['CHICAGO,', 'IL', '60627']\n",
    "data[76 - 19][0][-1][3] = ['ELLICOTT', 'CITY,', 'MD', '21043']\n",
    "data[78 - 19][2][-1][3] = ['BROCKTON,', 'HA', '02403']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 40\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "#find_seps([word[0] for word in words], 10, True)\n",
    "seps = [209, 385]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 86\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "#find_seps([word[0] for word in words], 10, True)\n",
    "seps = [200, 385]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 98\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "#find_seps([word[0] for word in words], 10, True)\n",
    "seps = [200, 385]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 73\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "#find_seps([word[0] for word in words], 10, True)\n",
    "seps = [196, 375]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 71\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "# find_seps([word[0] for word in words], 10, True)\n",
    "seps = [195]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[132 - 19][1][7] = [[\"U.S. PENITENTIARY\"],\n",
    "    ['LEWISBURG,', 'PA', '17837'],\n",
    " ['I', '717', 'l', \"523-'1251\"],\n",
    " ['Drug', 'Abuse', 'Treatment', 'Unit'],\n",
    " ['LEWISTOWN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[77 - 19][0][5][3] = ['ROCKVILLE,', 'HD', '208S0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[166 - 19][0] = [[['HOGAR', 'CREA-YABUCOA'],\n",
    "  ['SALIDA', 'BO', 'CAMINO', 'NUEVO'],\n",
    "  ['P.O.', 'BOX', '713'],\n",
    "  ['YABUCOA,', 'PR', '00767'],\n",
    "  ['(809)', '761-', '0715'],\n",
    "  ['Drug', 'Abuse', 'Treatment', 'Unit']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 77\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "seps = [190, 375]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 96\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "#find_seps([word[0] for word in words], 10, True)\n",
    "seps = [190, 375]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 26\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "#find_seps([word[0] for word in words], 10, True)\n",
    "seps = [230, 425]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pagen = 97\n",
    "words = doc[pagen - 1].getText(\"words\")\n",
    "words = [word for word in words if word[1] > 40 and word[1] < 695]\n",
    "#find_seps([word[0] for word in words], 10, True)\n",
    "seps = [190, 370]\n",
    "cols = []\n",
    "cols.append([word for word in words if word[0] < seps[0]])\n",
    "cols.append([word for word in words if word[0] > seps[0] and word[0] < seps[1]])\n",
    "cols.append([word for word in words if word[0] > seps[1]])\n",
    "\n",
    "page = []\n",
    "for col in cols:\n",
    "    col = split_rows(col, 5)\n",
    "    page.append(split_units(col, 10))\n",
    "\n",
    "data[pagen - 19] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[107 - 19][1][5] = [['CITY', 'OF', 'BUFFALO', 'OHR'],\n",
    " ['ELLICOTT/MASTEN', 'COMM', 'COUNSELING', 'CENTER'],\n",
    " ['560', '-', '562', 'WILLIAM', 'STREET'],\n",
    " ['BUFFALO,', 'NY', '14204'],\n",
    " ['I716l', '855-4069'],\n",
    " ['Drug', 'Abuse', 'Treatment', 'Unit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[107 - 19][2][2] = [['MENTAL', 'HEALTH', 'SERVICES', 'CORP', 'VI'], ['LOWER', 'WEST', 'SIDE', 'DRUG', 'ABUSE', 'PROGRAM'],\n",
    "                        ['485', 'NIAGARA', 'STREET'], ['BUFFALO,', 'NY', '14201'],\n",
    "                       ['I716l', '856-2000'], ['Drug', 'Abuse', 'Treatment', 'Unit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data[129 - 19][0][3] = [['HID', 'COLUMBIA', 'CENTER', 'FOR', 'LIVING'],\n",
    " ['400', 'EAST', 'FIFTH', 'STREET'],\n",
    " ['COURTHOUSE', 'ANNEX', 'A', 'ROOM', '106'],\n",
    " ['THE', 'DALLES,', 'OR', '97058'],\n",
    " ['(503)', '296-5452'],\n",
    " ['Alcoholism/Drug', 'Abuse', 'Treatment', 'Unit']]\n",
    "\n",
    "data[129 - 19][0][4] = [['TILLAMOOK', 'COUNTY'],\n",
    " ['COMM', 'COUNSELING', 'SERVICES', 'DRUG', 'PROGRAM'],\n",
    " ['2405', 'FIFTH', 'STREET'],\n",
    " ['TILLAMOOK,', 'OR', '97141'],\n",
    " ['(503)', '842-8201'],\n",
    " ['Drug', 'Abuse', 'Treatment', 'Unit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean final data\n",
    "- Replaced \"A venue\" with \"A venue\" in Address1\n",
    "- Split ZIP code into two if in the format \"35294-0018\"\n",
    "- To-do:\n",
    "    - Clean up the wrong letters/numbers in address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name1</th>\n",
       "      <th>Name2</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Address3</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP_Code</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALEXANDER CITY WORK RELEASE CENTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P.O. BOX 705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALEXANDER CITY</td>\n",
       "      <td>AL</td>\n",
       "      <td>35010.0</td>\n",
       "      <td>(205)234-7533</td>\n",
       "      <td>Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALHOUN-CLEDURNE MENTAL HEALTH CENTER</td>\n",
       "      <td>SUBSTANCE ABUSE PROGRAM</td>\n",
       "      <td>331 EAST EIGHTH AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ANNISTON</td>\n",
       "      <td>AL</td>\n",
       "      <td>36202.0</td>\n",
       "      <td>(205)236-3403</td>\n",
       "      <td>Alcoholism/Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOARD OF CORRECTIONS DRUG ABUSE</td>\n",
       "      <td>PROGRAM FOR ALABAMA INMATES</td>\n",
       "      <td>313 NORTH MAIN</td>\n",
       "      <td>P.O. BOX 266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATMORE</td>\n",
       "      <td>AL</td>\n",
       "      <td>36504.0</td>\n",
       "      <td>(205)368-1675</td>\n",
       "      <td>Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BESSEMER OUTPATIENT TREATMENT CENTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1830 THIRD AVENUE</td>\n",
       "      <td>SUITE 308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BESSEMER</td>\n",
       "      <td>AL</td>\n",
       "      <td>35020.0</td>\n",
       "      <td>(205)426-8020</td>\n",
       "      <td>Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALETHEIA HOUSE INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600 EIGHTH AVENUE SOUTH</td>\n",
       "      <td>SUITE W-110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>AL</td>\n",
       "      <td>35222.0</td>\n",
       "      <td>(205)324-6502</td>\n",
       "      <td>Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>GUAM COMMUNITY MENTAL HEALTH CENTER</td>\n",
       "      <td>DRUG TREATMENT PROGRAM</td>\n",
       "      <td>P.O. BOX AX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGANA</td>\n",
       "      <td>GU</td>\n",
       "      <td>96910.0</td>\n",
       "      <td>(671)646-9378</td>\n",
       "      <td>Alcoholism/Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>ST CROIX ALCOHOL AND</td>\n",
       "      <td>DRUG DEPENDENCY UNIT</td>\n",
       "      <td>153 RICHMOND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHRISTIANSTED, SAINT CROIX</td>\n",
       "      <td>VI</td>\n",
       "      <td>820.0</td>\n",
       "      <td>(809)773-5150</td>\n",
       "      <td>Alcoholism/Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>DEPARTMENT OF HEALTH SERVICES</td>\n",
       "      <td>OFFICE OF THE HIGH COMMISSIONER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HICOM HDQTRS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAIPAN, MARIANA ISLANDS</td>\n",
       "      <td>TT</td>\n",
       "      <td>96950.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alcoholism/Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>CATHOLIC SOCIAL SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 S A</td>\n",
       "      <td>BLOCK 2 LOT 5 TRACT 10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAGAT BARRIGADA</td>\n",
       "      <td>GU</td>\n",
       "      <td>96910.0</td>\n",
       "      <td>(671)734-3593</td>\n",
       "      <td>Alcoholism/Drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>ST THOMAS ALCOHOL AND</td>\n",
       "      <td>DRUG DEPENDEHCY UNIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OLD MUNICIPAL HOSPITAL</td>\n",
       "      <td>P.O. BOX 1442 CHARLOTTE AMALIE</td>\n",
       "      <td>SAINT THOMAS</td>\n",
       "      <td>VI</td>\n",
       "      <td>802.0</td>\n",
       "      <td>(809)774-7265</td>\n",
       "      <td>TERRITORY/PACIFIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3166 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name1                            Name2  \\\n",
       "0        ALEXANDER CITY WORK RELEASE CENTER                              NaN   \n",
       "1     CALHOUN-CLEDURNE MENTAL HEALTH CENTER          SUBSTANCE ABUSE PROGRAM   \n",
       "2           BOARD OF CORRECTIONS DRUG ABUSE      PROGRAM FOR ALABAMA INMATES   \n",
       "3      BESSEMER OUTPATIENT TREATMENT CENTER                              NaN   \n",
       "4                        ALETHEIA HOUSE INC                              NaN   \n",
       "...                                     ...                              ...   \n",
       "3161    GUAM COMMUNITY MENTAL HEALTH CENTER           DRUG TREATMENT PROGRAM   \n",
       "3162                   ST CROIX ALCOHOL AND             DRUG DEPENDENCY UNIT   \n",
       "3163          DEPARTMENT OF HEALTH SERVICES  OFFICE OF THE HIGH COMMISSIONER   \n",
       "3164               CATHOLIC SOCIAL SERVICES                              NaN   \n",
       "3165                  ST THOMAS ALCOHOL AND             DRUG DEPENDEHCY UNIT   \n",
       "\n",
       "                      Address1                Address2  \\\n",
       "0                 P.O. BOX 705                     NaN   \n",
       "1       331 EAST EIGHTH AVENUE                     NaN   \n",
       "2               313 NORTH MAIN            P.O. BOX 266   \n",
       "3            1830 THIRD AVENUE               SUITE 308   \n",
       "4     3600 EIGHTH AVENUE SOUTH             SUITE W-110   \n",
       "...                        ...                     ...   \n",
       "3161               P.O. BOX AX                     NaN   \n",
       "3162              153 RICHMOND                     NaN   \n",
       "3163                       NaN            HICOM HDQTRS   \n",
       "3164                     1 S A  BLOCK 2 LOT 5 TRACT 10   \n",
       "3165                       NaN  OLD MUNICIPAL HOSPITAL   \n",
       "\n",
       "                            Address3                        City State  \\\n",
       "0                                NaN              ALEXANDER CITY    AL   \n",
       "1                                NaN                    ANNISTON    AL   \n",
       "2                                NaN                      ATMORE    AL   \n",
       "3                                NaN                    BESSEMER    AL   \n",
       "4                                NaN                  BIRMINGHAM    AL   \n",
       "...                              ...                         ...   ...   \n",
       "3161                             NaN                       AGANA    GU   \n",
       "3162                             NaN  CHRISTIANSTED, SAINT CROIX    VI   \n",
       "3163                             NaN     SAIPAN, MARIANA ISLANDS    TT   \n",
       "3164                             NaN             PAGAT BARRIGADA    GU   \n",
       "3165  P.O. BOX 1442 CHARLOTTE AMALIE                SAINT THOMAS    VI   \n",
       "\n",
       "      ZIP_Code        Contact               Keys  \n",
       "0      35010.0  (205)234-7533               Drug  \n",
       "1      36202.0  (205)236-3403    Alcoholism/Drug  \n",
       "2      36504.0  (205)368-1675               Drug  \n",
       "3      35020.0  (205)426-8020               Drug  \n",
       "4      35222.0  (205)324-6502               Drug  \n",
       "...        ...            ...                ...  \n",
       "3161   96910.0  (671)646-9378    Alcoholism/Drug  \n",
       "3162     820.0  (809)773-5150    Alcoholism/Drug  \n",
       "3163   96950.0            NaN    Alcoholism/Drug  \n",
       "3164   96910.0  (671)734-3593    Alcoholism/Drug  \n",
       "3165     802.0  (809)774-7265  TERRITORY/PACIFIC  \n",
       "\n",
       "[3166 rows x 10 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"{}.csv\".format(1980))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if all state names are right\n",
    "for index, row in df.iterrows():\n",
    "    #print(row)\n",
    "    if len(row[6])!=2:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name1        object\n",
       "Name2        object\n",
       "Address1     object\n",
       "Address2     object\n",
       "Address3     object\n",
       "City         object\n",
       "State        object\n",
       "ZIP_Code    float64\n",
       "Contact      object\n",
       "Keys         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if all zip codes are correct\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correct in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if address 1 and 2 should actually be one line...\n",
    "for index, row in df.iterrows():\n",
    "    if row[0].split()[-1] == 'AND':\n",
    "        if pd.isnull(row[1]):\n",
    "            print(index)\n",
    "        else:\n",
    "            df.at[index, 'Name1'] = row[0] + ' ' + row[1]\n",
    "            df.at[index, 'Name2'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_zip(zipc):\n",
    "#     if '-' in zipc:\n",
    "#         return zipc.split('-')\n",
    "#     return [zipc, None]\n",
    "# #split zip-code if zip code is in the format xxxxx-xxxx\n",
    "# df['zip1'] = [split_zip(zipc)[0] for zipc in df['ZIP_Code']]\n",
    "# df['zip2'] = [split_zip(zipc)[1] for zipc in df['ZIP_Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('{}_c.csv'.format(1980), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
